{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2Qiv-f7dzeW"
   },
   "source": [
    "1. Dependency and data import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "9O1EUvyWdaM-",
    "outputId": "41807312-9aeb-499d-e134-7c86e19870c8"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow matplotlib tensorflow-datasets ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFM-MqCblx_B"
   },
   "source": [
    "- configure GPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "BNausfPheDMk"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# configure the GPUs\n",
    "gpu_settings = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpu_settings:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V2gPbyn2mFnf",
    "outputId": "8fd141a7-4423-4ebf-9632-8bca6ae4bf56"
   },
   "outputs": [],
   "source": [
    "# should have at least 1 gpu config\n",
    "gpu_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "LEK87jRgmVA3"
   },
   "outputs": [],
   "source": [
    "# bring the other dependencies and fashion mnist dataset\n",
    "import tensorflow_datasets as tfds\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "mJILekJqmvxE"
   },
   "outputs": [],
   "source": [
    "# download and import our dataset\n",
    "dataset = tfds.load('fashion_mnist', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7x5vpuAk5an"
   },
   "source": [
    "2. Visualize data and build data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "cKq0QkTQoJvX"
   },
   "outputs": [],
   "source": [
    "# transform data accordingly\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "xHcbFCugnhSH"
   },
   "outputs": [],
   "source": [
    "# set the connection(iterator)\n",
    "data_iterator = dataset.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "b5UfQKbJph-P",
    "outputId": "a8b07f32-94dd-482c-8c1e-3bd0fdf45b70"
   },
   "outputs": [],
   "source": [
    "# get data from pipeline\n",
    "data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "eYUnP83Bplii",
    "outputId": "86ce30e1-6786-4800-b0d0-c4ca9e780c07"
   },
   "outputs": [],
   "source": [
    "# visualize some images from the data set\n",
    "# set the subplot\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "# get a number of images (4)\n",
    "for index in range(4):\n",
    "  # get image and label\n",
    "  batch = data_iterator.next()\n",
    "  # plot image on a subplot\n",
    "  ax[index].imshow(np.squeeze(batch['image']))\n",
    "  # assign image label as plot title\n",
    "  ax[index].title.set_text(batch['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "9BszEEDHqJnr"
   },
   "outputs": [],
   "source": [
    "# function to scale and return images only\n",
    "# we do not need the labels, as we will generate undiscriminate outputs\n",
    "def scale_images(data):\n",
    "  image = data['image']\n",
    "  return image/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "upwsiPIxsrnB"
   },
   "outputs": [],
   "source": [
    "# load the dataset anew\n",
    "dataset = tfds.load('fashion_mnist', split='train')\n",
    "# run scale_images preprocessing on the dataset\n",
    "dataset = dataset.map(scale_images)\n",
    "# chache the dataset batch\n",
    "dataset = dataset.cache()\n",
    "# shuffle the dataset\n",
    "dataset = dataset.shuffle(50000)\n",
    "# set up batches of 128 images\n",
    "dataset = dataset.batch(128)\n",
    "# reduces bottleneck\n",
    "dataset = dataset.prefetch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j9BIlVWYt8om",
    "outputId": "b449fb15-da37-4aa1-ee48-c29c7629953b"
   },
   "outputs": [],
   "source": [
    "# view configuration of the batch\n",
    "dataset.as_numpy_iterator().next().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvrQ79pWsgaT"
   },
   "source": [
    "3. Build the neural network\n",
    "\n",
    "We will build two models, a generator and a discriminator. The generator will generate images based on the training data. The discriminator, on the other hand, will try to spot the fakes. Therefore, the models will be trained to do two contradictory tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "MqWvZUodvyDL"
   },
   "outputs": [],
   "source": [
    "# get sequential API for the generator and discriminator\n",
    "from tensorflow.keras.models import Sequential\n",
    "# get layers for the network\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "awQ-l_NDwoJv"
   },
   "outputs": [],
   "source": [
    "# function to build a generator\n",
    "def build_generator():\n",
    "  # initialize model\n",
    "  model = Sequential()\n",
    "  # reshapes random value to 7* 7* 28 px\n",
    "  model.add(Dense(7*7*128, input_dim = 128))\n",
    "  model.add(LeakyReLU(0.2))\n",
    "  model.add(Reshape((7,7,128)))\n",
    "\n",
    "  # upsampling first block\n",
    "  model.add(UpSampling2D())\n",
    "  model.add(Conv2D(128, 5, padding='same'))\n",
    "  model.add(LeakyReLU(0.2))\n",
    "\n",
    "  # upsampling second block\n",
    "  model.add(UpSampling2D())\n",
    "  model.add(Conv2D(128, 5, padding='same'))\n",
    "  model.add(LeakyReLU(0.2))\n",
    "\n",
    "  # convolutional first block\n",
    "  model.add(Conv2D(128, 4, padding='same'))\n",
    "  model.add(LeakyReLU(0.2))\n",
    "\n",
    "  # convolutional second block\n",
    "  model.add(Conv2D(128, 4, padding='same'))\n",
    "  model.add(LeakyReLU(0.2))\n",
    "\n",
    "  # final convolutional layer\n",
    "  model.add(Conv2D(1, 4, padding='same', activation='sigmoid'))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPsLxbBMxJ1t",
    "outputId": "6f64a78f-433d-4c3b-f9bd-9841e00d8a13"
   },
   "outputs": [],
   "source": [
    "# generate the test model\n",
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "h0NpWln5xX9D",
    "outputId": "542c6ff1-caff-4365-c0c6-b6d061569275"
   },
   "outputs": [],
   "source": [
    "# view summary\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "grTlHY2M58pb",
    "outputId": "0a34770e-c525-4975-d9f7-42c8a53d40c6"
   },
   "outputs": [],
   "source": [
    "# generate new clothes\n",
    "image = test.predict(np.random.randn(4, 128, 1))\n",
    "# set the subplot\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "# get a number of images (4)\n",
    "for index, img in enumerate(image):\n",
    "  # get image and label\n",
    "  ax[index].imshow(np.squeeze(img))\n",
    "  # assign image label as plot title\n",
    "  ax[index].title.set_text(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "t_BAvwXQ73sz"
   },
   "outputs": [],
   "source": [
    "# build the discriminator\n",
    "def build_discriminator():\n",
    "  model = Sequential()\n",
    "\n",
    "  # convolutional first block\n",
    "  model.add(Conv2D(32, 5, input_shape=(28,28,1)))\n",
    "  model.add(LeakyReLU(0.2))\n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  # convolutional second block\n",
    "  model.add(Conv2D(64, 5))\n",
    "  model.add(LeakyReLU(0.2))\n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  # convolutional third block\n",
    "  model.add(Conv2D(128, 5))\n",
    "  model.add(LeakyReLU(0.2))\n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  # convolutional fourth block\n",
    "  model.add(Conv2D(256, 5))\n",
    "  model.add(LeakyReLU(0.2))\n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  # flatten and pass to dense layer\n",
    "  model.add(Flatten())\n",
    "  model.add(Dropout(0.4))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TyppGZwJ9KAZ",
    "outputId": "ecfb891f-c56f-4b5c-99be-374f5a76e90d"
   },
   "outputs": [],
   "source": [
    "# instantiate a discriminator\n",
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "X-3G69zn9Mqn",
    "outputId": "69081945-acd5-4d4c-c438-44595dcc4ac0"
   },
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rNV5qlh-UnI",
    "outputId": "f43c2ae5-c1cc-4efe-f683-6ae9c4c08888"
   },
   "outputs": [],
   "source": [
    "# test the discriminator\n",
    "discriminator.predict(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPShhhaTAUdq"
   },
   "source": [
    "4. Training loops\n",
    "\n",
    "We will prepare custom training loops to train the generator and discriminator simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wUfmv1kB0JR"
   },
   "source": [
    "4.1 Optimizer and loss setup\n",
    "\n",
    "Ensure that the learning rate for generative is greater than discriminative, in order to ensure that the discriminative does not outlearn generative significantly, swekering the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "Irtf4qib_u4N"
   },
   "outputs": [],
   "source": [
    "# use adam for optimization and binary cross entropy for loss\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "qUy8blhWDXUk"
   },
   "outputs": [],
   "source": [
    "# define generative and discriminative optimization\n",
    "generation_optimization = Adam(learning_rate = 0.0001)\n",
    "discrimination_optimization = Adam(learning_rate=0.00001)\n",
    "# define generative and discriminative losses\n",
    "generation_loss = BinaryCrossentropy()\n",
    "discrimination_loss = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_6ozlKKECkj"
   },
   "source": [
    "4.2 Subclass model building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "QU7a2-7qEBfS"
   },
   "outputs": [],
   "source": [
    "# import the base model class for our training step\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "ggump2k0EPXC"
   },
   "outputs": [],
   "source": [
    "# define the governing class for the training\n",
    "class fashionista(Model):\n",
    "  def __init__(self, generator, discriminator, *args, **kwargs):\n",
    "    # pass to base class\n",
    "    super().__init__(*args, **kwargs)\n",
    "\n",
    "    # create attributes for generator and discriminator\n",
    "    self.generator = generator\n",
    "    self.discriminator = discriminator\n",
    "\n",
    "  def compile(self, gopt, dopt, gloss, dloss, *args, **kwargs):\n",
    "    # compile with base class\n",
    "    super().compile(*args, **kwargs)\n",
    "\n",
    "    # attributes for optimization and losses\n",
    "    self.gopt = gopt\n",
    "    self.dopt = dopt\n",
    "    self.gloss = gloss\n",
    "    self.dloss = dloss\n",
    "\n",
    "  def train_step(self, batch):\n",
    "    # get the batch of data (128 in our case)\n",
    "    real_images = batch\n",
    "    fake_images = self.generator(tf.random.normal((128, 128, 1)), training=False)\n",
    "\n",
    "    # train the discriminator\n",
    "    with tf.GradientTape() as d_tape:\n",
    "\n",
    "      # pass real and fake imnages to discriminator\n",
    "      y_hat_real = self.discriminator(real_images, training=True)\n",
    "      y_hat_fake = self.discriminator(fake_images, training=True)\n",
    "      y_hat_real_fake = tf.concat([y_hat_real, y_hat_fake], axis=0)\n",
    "\n",
    "      # label the images as real and fake\n",
    "      y_real_fake = tf.concat([tf.zeros_like(y_hat_real), tf.ones_like(y_hat_fake)], axis=0)\n",
    "\n",
    "      # add noise to the output to avoid outlearning\n",
    "      noise_real = 0.15*tf.random.uniform(tf.shape(y_hat_real))\n",
    "      noise_fake = -0.15*tf.random.uniform(tf.shape(y_hat_fake))\n",
    "      y_real_fake += tf.concat([noise_real, noise_fake], axis=0)\n",
    "\n",
    "      # calculate loss\n",
    "      total_dis_loss = self.dloss(y_real_fake, y_hat_real_fake)\n",
    "\n",
    "    # apply learning with backpropagation method\n",
    "    d_gradient = d_tape.gradient(total_dis_loss, self.discriminator.trainable_variables)\n",
    "    self.dopt.apply_gradients(zip(d_gradient, self.discriminator.trainable_variables))\n",
    "\n",
    "    with tf.GradientTape() as g_tape:\n",
    "      # generate new images\n",
    "      gen_images = self.generator(tf.random.normal((128, 128, 1)), training=True)\n",
    "\n",
    "      # create predicted labels\n",
    "      predicted_labels = self.discriminator(gen_images, training=False)\n",
    "\n",
    "      # calculate loss\n",
    "      total_gen_loss = self.gloss(tf.zeros_like(predicted_labels), predicted_labels)\n",
    "\n",
    "    # apply backpropagation\n",
    "    ggrad = g_tape.gradient(total_gen_loss, self.generator.trainable_variables)\n",
    "    self.gopt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
    "\n",
    "    return {\"dis_loss\": total_dis_loss, \"gen_loss\": total_gen_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "tzY0YiQvMin0"
   },
   "outputs": [],
   "source": [
    "# create instance of the model\n",
    "fashioner = fashionista(generator=test, discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "mHTdpz1_MzEB"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "fashioner.compile(gopt=generation_optimization, dopt=discrimination_optimization, gloss=generation_loss, dloss=discrimination_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdwwFTPaMe2_"
   },
   "source": [
    "4.3 Callback Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "T4EQeuDoMWWc"
   },
   "outputs": [],
   "source": [
    "# import the dependencies\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "3l5fXF1jQ0Am"
   },
   "outputs": [],
   "source": [
    "class ModelMonitor(Callback):\n",
    "  def __init__(self, num_img=3, latent_dim=128):\n",
    "    self.num_img = num_img\n",
    "    self.latent_dim = latent_dim\n",
    "  def on_epoch_end(self, epoch, legs=None):\n",
    "    random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim, 1))\n",
    "    generated_images = self.model.generator(random_latent_vectors)\n",
    "    generated_images *= 255\n",
    "    generated_images.numpy()\n",
    "    for i in range(self.num_img):\n",
    "      img = array_to_img(generated_images[i])\n",
    "      img.save(os.path.join('images', f'generated_image_{epoch}_{i}.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEZZAbk2Q3-d"
   },
   "source": [
    "4.3 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8gPk0D1zQ9EC",
    "outputId": "58b9fedf-a809-4c2b-cd22-618fa02de699"
   },
   "outputs": [],
   "source": [
    "dataset.as_numpy_iterator().next().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2IJ3mCgQ3Uf",
    "outputId": "8f1c7c0b-6a59-47c5-8605-26e6e65e72b1"
   },
   "outputs": [],
   "source": [
    "# run the loop\n",
    "history = fashioner.fit(dataset, epochs=20, callbacks=[ModelMonitor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmpNJpmgUJAY"
   },
   "source": [
    "4.4 Performance Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6WmDyC7RP4V"
   },
   "outputs": [],
   "source": [
    "# use history and matplotlib for loss visualization\n",
    "plt.suptitle('Overall loss')\n",
    "plt.plot(history.history['dis_loss'], label='Discriminator loss')\n",
    "plt.plot(history.history['gen_loss'], label='Generator loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-JAYjL0U7nU"
   },
   "source": [
    "5. Generator testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "MNwZRDDcaNzW",
    "outputId": "8b648d0d-e1ae-4d82-9435-97e79aacb270"
   },
   "outputs": [],
   "source": [
    "# generate images\n",
    "# use pre_wieghted tests for faster results\n",
    "generator.load_weights(os.path.join('archive', 'generatormodel.h5'))\n",
    "\n",
    "images = generator.predict(tf.random.normal((16, 128, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "Lbsnl9MzasK2",
    "outputId": "5fdfce5d-ff28-4636-b274-7dfaf73fedb8"
   },
   "outputs": [],
   "source": [
    "# use the images to generate fashionable items images\n",
    "fig, ax = plt.subplots(ncols=4, nrows=4, figsize=(20, 20))\n",
    "for x in range(4):\n",
    "  for y in range(4):\n",
    "    ax[x][y].imshow(images[(x+1)* (y+1)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPkt6tBGbb9Z"
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "\n",
    "generator.save('generator_dk.h5')\n",
    "discriminator.save('discriminator.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
